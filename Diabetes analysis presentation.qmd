---
title: "Smart Diagnosis"
subtitle: "Predicting Diabetes using Logistic Regression"
author: "Inder Khera, Jenny Zhang, Jessica Kuo, Javier Martinez"
format: revealjs
include-in-header:
  - text: |
      <style>
      #title-slide .subtitle {
        font-size: 1.5em;
      }
      </style>
slide-number: true
jupyter: python3
css: styles.css
---

### Why is Diabetic Study  Important?
- Affects millions globally
- Identifying predictors helps:
  - Focus on preventive measures
  - Reduce healthcare costs  
  - Improve the quality of life 

#### Focus of Study:
- Use logistic regression model to evaluate diabetes prediction

---

### Previous Research
- [Use of Neural Networks (Jack W Smith, et. al)](https://pmc.ncbi.nlm.nih.gov/articles/PMC2245318/)
- [Logistic Regression (UCI Machine Learning)](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database/data)
- [Random Forestion (Quan Zou, et. al)](https://pmc.ncbi.nlm.nih.gov/articles/PMC6232260/)

#### What is unique about our study?
- Use Logistic Regression for easier interpretation
- Use of Data Validation for better accuracy

---

### Why use a Logistic Regression model?
- Study is based on Binary Classification
- Feature coefficients directly reflect importance
- Focus is on probabilities:
  - More insight than just classifications
  - Helps determine confidence level of diagnosis

---

### Dataset Scope

- Total 768 female patients
- Pima Indian heritage
- All at least 21 years old

<br/>

![](figures/nih.png){.nostretch fig-align="center" width="600"}

---

### Feature Descriptions

::: {.feature-description}
| **Feature**                 | **Type**      | **Units/Description**                                                                 |
|-----------------------------|---------------|---------------------------------------------------------------------------------------|
| <span style="color:#4A90E2">**Pregnancies**</span>        | Numerical     | Number of pregnancies                                                                 |
| <span style="color:#4A90E2">**Age**</span>                | Numerical     | Age in years                                                                          |
| <span style="color:#4A90E2">**Glucose**</span>            | Numerical     | Plasma glucose concentration in mg/dL                                                |
| <span style="color:#4A90E2">**BloodPressure**</span>      | Numerical     | Diastolic blood pressure measurement in mm Hg                                         |
| <span style="color:#4A90E2">**Insulin**</span>            | Numerical     | Insulin level in mu U/ml                                                 |
| <span style="color:#4A90E2">**SkinThickness**</span>      | Numerical     | Triceps skin fold thickness in mm (estimates body fat)                               |
| <span style="color:#FF9F43">**BMI**</span>                | Numerical     | Body Mass Index in kg/m² (indicates body fat)                                         |
| <span style="color:#FF9F43">**DiabetesPedigreeFunction**</span> | Numerical | Diabetes likelihood score based on family history                                    |
| **Outcome**                 | Categorical   | <span style="background:#FF6B6B; padding:2px 5px; border-radius:3px; color:white;">Diabetic</span> / <span style="background:#77DD77; padding:2px 5px; border-radius:3px; color:white;">Non-Diabetic</span> |
:::

- <span style="color:#4A90E2">▉</span> **Direct Health measurements**  
- <span style="color:#FF9F43">▉</span> **Calculated health metrics**  

---

### Exploratory Data Analysis

![](figures/histogram_imbalance.png)

---

### Exploratory Data Analysis

![](figures/eda.png){.center}

---

### Data Validation 

![](figures/glucose_outlier.png)

- Column constraints: 
  - Free of outliers & invalid values
  - Based on medically plausible range

- Ensure data integrity: 
  - No duplicate or empty rows
  - No columns with mixed data types

---

### Data Validation (cont'd)

![](figures/correlation.png){width=150%}

- Identify potential multicollinearity
- Ensure feature correlation does not pass 0.7 threshold
  

---

### Analysis Methodology

- Data split: 70% training, 30% testing
- Features: 
  - Structured numeric data 
  - No missing values
- Preprocessing: 
  - Standardization through `StandardScaler()`
---

### Analysis Methodology (cont'd)

- Model evaluation metric: Accuracy
- Baseline model: `DummyClassifer` 
- Choosen model: `LogisticRegression`
- Hyperparameter tuning: 
  - Optimize regularization strength `C` between $10 ^{-5}$ and $10 ^{5}$ 
  - Use method `RandomizedSearchCV()`

---

### Reproducible Data Pipeline

- The pipeline followed a **modular structure**, ensuring:

- **Reusability**
- **Interdependency**
- **Automation**

![](figures/data_pipeline.png)

---

### Results - Feature Importance

- Feature importance measured by coefficients

![](figures/coeff_table.png)

---

### Results - Model Evaluation

- <u>Dummy Classifier:</u>
  - **Cross validation accuracy = 0.672**
- <u>Logistic Regression:</u>
  - Best hyperparameter C $\approx$ 0.027
  - Cross validation: 
    - Training accuracy = 0.786
    - Validation accuracy = 0.781
  - **Test set accuracy = 0.750**

---

### Results - Confusion Matrix

:::: {.columns}

::: {.column width="40%"}
<br/>

#### 216 total test cases

**54 misclassifications**

- *41 false negatives*
 
- *13 false positives*
:::

::: {.column width="60%"}
![](figures/confusion_matrix_plot.png){}
:::

::::

---

### Results - PR and ROC Curve

- Model performance does not achieve optimal trade-off across all thresholds.

:::: {.columns}

::: {.column width="50%"}
![](figures/precision_recall_plot.png)
:::

::: {.column width="50%"}
![](figures/roc_curve.png)
:::

::::

---

### Results - Clinical Utility

- Visualizing predicted probabilities to help clinicians assess model confidence.

![](figures/predict_chart.png){.nostretch fig-align="center" width="750"}

---

### Discussion - Model Performance
- Clinical Relevance: effective screening tool
- Enhancement Approaches:
    - Examine misclassified observations

---

### Discussion - Enhancement Opportunities
- Explore feature engineering
- Alternative classifiers:
    - Random Forest
    - k-Nearest Neighbours (k-NN)
    - Support Vector Classifier (SVC)

---

### Limitations & Future Directions
- Dataset Limitations
- Future Data Exploration
    - Collaborate with data collectors
    - Combine with external datasets
        - Broaden demographic coverage
        - Enable comprehensive insights and greater applicabilit

---

### Conclusion - Key Findings
- Logistic regression vs. Dummy Classifier.
- Key predictors/features: Glucose (most influential) BMI, pregnancies.
- Challenges: 54 misclassifications, including 41 false negatives, highlight risks of undiagnosed cases.
- Clinical Potential: initial screening tool, data-driven approach to improve outcomes and reduce complications.

---

### Conclusion - Recommendations
- Recommendations for Improvement:
    - Feature engineering
    - Test alternative ML models 
    - Incorporate additional data (e.g. Lifestyle factors, Genetic information etc.)
    - Include probability estimates to aid clinical decision-making.

--- 

### References
<font size="5"> 

- Dua, Dheeru, and Casey Graff. 2017. “Pima Indians Diabetes Database.” https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database/data.

- Harris, Charles R, K Jarrod Millman, Stéfan J Van Der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, et al. 2020. “Array Programming with NumPy.” Nature 585 (7825): 357–62. https://doi.org/10.1038/s41586-020-2649-2.

- McKinney, Wes. 2010. “Data Structures for Statistical Computing in Python.” In Proceedings of the 9th Python in Science Conference, edited by Stéfan van der Walt and Jarrod Millman, 51–56. https://doi.org/10.25080/Majora-92bf1922-00a.

- Ostblom, Joakim. 2021. “Altair_ally: Enhancing Altair for Statistical Visualization.” https://github.com/jostblom/altair_ally.

- Pedregosa, Fabian, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, et al. 2011. “Scikit-Learn: Machine Learning in Python.” The Journal of Machine Learning Research 12: 2825–30. https://doi.org/10.48550/arXiv.1201.0490.

- Van Rossum, Guido, and Fred L. Drake. 2009. Python 3 Reference Manual. Scotts Valley, CA: CreateSpace.

- VanderPlas, Jake. 2018. “Altair: Interactive Statistical Visualizations for Python.” Journal of Open Source Software 3 (7825, 32): 1057. https://doi.org/10.21105/joss.01057.

</font>